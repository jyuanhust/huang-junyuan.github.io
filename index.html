<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://huang-junyuan.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://huang-junyuan.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://huang-junyuan.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://huang-junyuan.github.io/"><title>Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><a href="/" class="logo" rel="start"><p class="artboard">Mi Manchi</p><h1 itemprop="name headline" class="title">yuan</h1></a><p class="meta" itemprop="description">= Whatever is worth doing at all is worth doing well =</p></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipexe4oykj20zk0m87ji.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giclhtuo6nj20zk0m8ttm.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipeyhsblkj20zk0m81kx.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giph47e9vtj20zk0m8x6l.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gicljgocqbj20zk0m8e81.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giclffsa1cj20zk0m811l.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="index wrap"><h2 class="divider">置顶文章</h2><div class="segments sticky"><article class="item"><div class="cover"><a href="/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/" itemprop="url" title="pytorch入门"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gicivghyooj20zk0m8dir.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-07-22 10:21:48"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-07-22T10:21:48+08:00">2022-07-22</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>51k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>46 分钟</span></span></div><h3><a href="/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/" itemprop="url" title="pytorch入门">pytorch入门</a></h3><div class="excerpt"># 初始 # 前言 使用 conda 安装时不用另外装 cuda 和 cudnn，它自己会去装 查看 cuda 版本 nvidia-smi conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu110 实测 cuda11.0 可以 cuda10.2 的 # 换源 conda config --add...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/" itemprop="url" title="pytorch入门" class="btn">more...</a></div></article></div><h2 class="divider">精选分类</h2><div class="cards"><section class="item"><div class="cover" data-background-image="/test/cover.jpg"><h2 class="title">test</h2></div><div class="info"><div class="ribbon"><a href="/categories/test/" itemprop="url" title="test">test</a></div><div class="inner"><ul class="posts"><li><a title="test" href="/2022/06/26/test/test/">test</a></li><li><a title="test2" href="/2022/08/29/test/test2/">test2</a></li></ul><div class="meta footer"><span><i class="ic i-file"></i>2 篇文章</span></div><a href="/categories/test/" itemprop="url" title="test" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/ai/cv/cover.jpg"><h2 class="title">cv</h2><span>ai</span></div><div class="info"><div class="ribbon"><a href="/categories/ai/cv/" itemprop="url" title="cv">cv</a></div><div class="inner"><ul class="posts"><li><a title="GAN" href="/2022/08/25/ai/cv/GAN/">GAN</a></li><li><a title="MobileNet" href="/2022/08/25/ai/cv/MobileNet/">MobileNet</a></li><li><a title="OpenCV教程" href="/2022/07/21/ai/cv/OpenCV%E6%95%99%E7%A8%8B/">OpenCV教程</a></li><li><a title="OpenCV轮廓检测" href="/2022/07/21/ai/cv/OpenCV%E8%BD%AE%E5%BB%93%E6%A3%80%E6%B5%8B/">OpenCV轮廓检测</a></li><li><a title="face_alignment：face_alignment库的简介、安装、使用方法" href="/2022/08/24/ai/cv/face-alignment%EF%BC%9Aface-alignment%E5%BA%93%E7%9A%84%E7%AE%80%E4%BB%8B%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">face_alignment：face_alignment库的简介、安装、使用方法</a></li><li><a title="ncnn和opencv在vs2022上创建工程推理示例" href="/2022/07/22/ai/cv/ncnn%E5%92%8Copencv%E5%9C%A8vs2022%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B/">ncnn和opencv在vs2022上创建工程推理示例</a></li></ul><div class="meta footer"><span><a href="/categories/ai/" itemprop="url" title="ai"><i class="ic i-flag"></i>ai</a> </span><span><i class="ic i-file"></i>10 篇文章</span></div><a href="/categories/ai/cv/" itemprop="url" title="cv" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/ai/nlp/cover.jpg"><h2 class="title">nlp</h2><span>ai</span></div><div class="info"><div class="ribbon"><a href="/categories/ai/nlp/" itemprop="url" title="nlp">nlp</a></div><div class="inner"><ul class="posts"><li><a title="NLP和transformer大类概述" href="/2022/09/21/ai/nlp/nlp-transformer%E6%A6%82%E8%BF%B0/">NLP和transformer大类概述</a></li><li><a title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系" href="/2022/08/24/ai/nlp/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/">PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系</a></li><li><a title="Subword算法" href="/2022/09/22/ai/nlp/Subword%E7%AE%97%E6%B3%95/">Subword算法</a></li><li><a title="Summarization - huggingface" href="/2022/08/05/ai/nlp/Summarization-huggingface/">Summarization - huggingface</a></li><li><a title="nlp的数据集" href="/2022/08/25/ai/nlp/nlp%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/">nlp的数据集</a></li><li><a title="pytorch中LSTM的output和hidden关系" href="/2022/08/24/ai/nlp/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/">pytorch中LSTM的output和hidden关系</a></li></ul><div class="meta footer"><span><a href="/categories/ai/" itemprop="url" title="ai"><i class="ic i-flag"></i>ai</a> </span><span><i class="ic i-file"></i>9 篇文章</span></div><a href="/categories/ai/nlp/" itemprop="url" title="nlp" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/ai/pytorch/cover.jpg"><h2 class="title">pytorch</h2><span>ai</span></div><div class="info"><div class="ribbon"><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch">pytorch</a></div><div class="inner"><ul class="posts"><li><a title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()" href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/">PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()</a></li><li><a title="Pytorch中transforms.RandomResizedCrop()等图像操作" href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/">Pytorch中transforms.RandomResizedCrop()等图像操作</a></li><li><a title="Pytorch函数expand()详解" href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/">Pytorch函数expand()详解</a></li><li><a title="Pytorch的data.norm（几种范数(norm)的详细介绍）" href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/">Pytorch的data.norm（几种范数(norm)的详细介绍）</a></li><li><a title="Pytorch通过requires_grad固定部分参数进行网络训练" href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/">Pytorch通过requires_grad固定部分参数进行网络训练</a></li><li><a title="argmax-torch" href="/2022/07/25/ai/pytorch/argmax-torch/">argmax-torch</a></li></ul><div class="meta footer"><span><a href="/categories/ai/" itemprop="url" title="ai"><i class="ic i-flag"></i>ai</a> </span><span><i class="ic i-file"></i>12 篇文章</span></div><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/backend/cover.jpg"><h2 class="title">后端</h2></div><div class="info"><div class="ribbon"><a href="/categories/backend/" itemprop="url" title="后端">后端</a></div><div class="inner"><ul class="posts"><li><a title="django" href="/categories/backend/django/">django</a></li></ul><div class="meta footer"><span><i class="ic i-file"></i>1 个子项，11 篇文章</span></div><a href="/categories/backend/" itemprop="url" title="后端" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/frontend/cover.jpg"><h2 class="title">前端</h2></div><div class="info"><div class="ribbon"><a href="/categories/frontend/" itemprop="url" title="前端">前端</a></div><div class="inner"><ul class="posts"><li><a title="Node.js" href="/categories/frontend/Node-js/">Node.js</a></li><li><a title="css" href="/categories/frontend/css/">css</a></li><li><a title="javascript" href="/categories/frontend/javascript/">javascript</a></li><li><a title="vue" href="/categories/frontend/vue/">vue</a></li><li><a title="CSS" href="/2022/07/24/frontend/CSS/css/">CSS</a></li><li><a title="CSS布局" href="/2022/09/08/frontend/CSS/CSS%E5%B8%83%E5%B1%80/">CSS布局</a></li></ul><div class="meta footer"><span><i class="ic i-file"></i>4 个子项，31 篇文章</span></div><a href="/categories/frontend/" itemprop="url" title="前端" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/frontend/vue/cover.jpg"><h2 class="title">vue</h2><span>前端</span></div><div class="info"><div class="ribbon"><a href="/categories/frontend/vue/" itemprop="url" title="vue">vue</a></div><div class="inner"><ul class="posts"><li><a title="mediapipe-vue" href="/categories/frontend/vue/mediapipe-vue/">mediapipe-vue</a></li><li><a title="Less" href="/2022/09/11/frontend/vue/Less/">Less</a></li><li><a title="VUE3新特性" href="/2022/08/26/frontend/vue/vue3%E6%96%B0%E7%89%B9%E6%80%A7/">VUE3新特性</a></li><li><a title="pinia" href="/2022/08/26/frontend/vue/pinia/">pinia</a></li><li><a title="vuex" href="/2022/08/26/frontend/vue/vuex/">vuex</a></li><li><a title="vue基础入门_" href="/2022/08/24/frontend/vue/vue%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8-1/">vue基础入门_</a></li></ul><div class="meta footer"><span><a href="/categories/frontend/" itemprop="url" title="前端"><i class="ic i-flag"></i>前端</a> </span><span><i class="ic i-file"></i>1 个子项，18 篇文章</span></div><a href="/categories/frontend/vue/" itemprop="url" title="vue" class="btn">more...</a></div></div></section><section class="item"><div class="cover" data-background-image="/computer-science/cover.jpg"><h2 class="title">computer-science</h2></div><div class="info"><div class="ribbon"><a href="/categories/computer-science/" itemprop="url" title="computer-science">computer-science</a></div><div class="inner"><ul class="posts"><li><a title="计算机组成原理" href="/categories/computer-science/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/">计算机组成原理</a></li><li><a title="计算机网络" href="/categories/computer-science/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></li></ul><div class="meta footer"><span><i class="ic i-file"></i>2 个子项，6 篇文章</span></div><a href="/categories/computer-science/" itemprop="url" title="computer-science" class="btn">more...</a></div></div></section></div><h2 class="divider">文章列表</h2><div class="segments posts"><article class="item"><div class="cover"><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" itemprop="url" title="NLP和transformer大类概述"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gipeuibk9fj20zk0m8ay2.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>18k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>16 分钟</span></span></div><h3><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" itemprop="url" title="NLP和transformer大类概述">NLP和transformer大类概述</a></h3><div class="excerpt"># 微调掩码语言模型 对于许多涉及 Transformer 模型的 NLP 程序，你可以简单地从 Hugging Face Hub 中获取一个预训练的模型，然后直接在你的数据上对其进行微调，以完成手头的任务。只要用于预训练的语料库与用于微调的语料库没有太大区别，迁移学习通常会产生很好的结果。 但是，在某些情况下，你需要先微调数据上的语言模型，然后再训练特定于任务的 head。例如，如果您的数据集包含法律合同或科学文章，像 BERT 这样的普通 Transformer...</div><div class="meta footer"><span><a href="/categories/ai/huggingface/" itemprop="url" title="huggingface"><i class="ic i-flag"></i>huggingface</a></span></div><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" itemprop="url" title="NLP和transformer大类概述" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/12/ai/nlp/huggingface/%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/note/" itemprop="url" title="NLP和transformer大类概述"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gipeu1usa7j20zk0m8b29.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>192</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/12/ai/nlp/huggingface/%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/note/" itemprop="url" title="NLP和transformer大类概述">NLP和transformer大类概述</a></h3><div class="excerpt">对于 head 的理解，预训练的模型可能自己本身是带有 head 的，如果使用 autoModel 的话，那么就会自动加上这个 Head。但如果想要利用这个预训练模型，然后调整下游任务，那么就要换上特定的 token，这是就得使用 AutoModelFor...，这样模型就会自动替换原先的 head，然后就可以从头开始训练了。 但是因为还是使用原来的模型，所以 AutoTokenizer 还是可以继续用的。</div><div class="meta footer"><span><a href="/categories/ai/huggingface/" itemprop="url" title="huggingface"><i class="ic i-flag"></i>huggingface</a></span></div><a href="/2022/11/12/ai/nlp/huggingface/%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/note/" itemprop="url" title="NLP和transformer大类概述" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" itemprop="url" title="NLP和transformer大类概述"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1giciundwu5j20zk0m8n9e.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>11k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>10 分钟</span></span></div><h3><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" itemprop="url" title="NLP和transformer大类概述">NLP和transformer大类概述</a></h3><div class="excerpt"># 处理数据 下面是我们用模型中心的数据在 PyTorch 上训练句子分类器的一个例子： import torchfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification# Same as beforecheckpoint = &quot;bert-base-uncased&quot;tokenizer = AutoTokenizer.from_pretrained(checkpoint)model =...</div><div class="meta footer"><span><a href="/categories/ai/huggingface/" itemprop="url" title="huggingface"><i class="ic i-flag"></i>huggingface</a></span></div><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" itemprop="url" title="NLP和transformer大类概述" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/11/computer-science/%E6%95%B0%E7%AB%9E/%E6%95%B0%E7%AB%9E/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1giclflwv2aj20zk0m84qp.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-11 00:15:22"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-11T00:15:22+08:00">2022-11-11</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>0</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/11/computer-science/%E6%95%B0%E7%AB%9E/%E6%95%B0%E7%AB%9E/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt"></div><a href="/2022/11/11/computer-science/%E6%95%B0%E7%AB%9E/%E6%95%B0%E7%AB%9E/" itemprop="url" title="未命名" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/09/ai/pytorch/MAML/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gicljitigmj20zk0m87fp.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-09 21:28:37"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-09T21:28:37+08:00">2022-11-09</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>43</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/09/ai/pytorch/MAML/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt"># 参考资料 https://zhuanlan.zhihu.com/p/448715415</div><a href="/2022/11/09/ai/pytorch/MAML/" itemprop="url" title="未命名" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/06/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/%E5%AE%9E%E8%AE%AD3-%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2Select%E4%B9%8B%E4%B8%80/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gipetv6p75j20zk0m8x6p.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-06 20:00:22"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-06T20:00:22+08:00">2022-11-06</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>488</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/06/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/%E5%AE%9E%E8%AE%AD3-%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2Select%E4%B9%8B%E4%B8%80/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt">having 和 where https://www.cnblogs.com/fanguangdexiaoyuer/p/6268211.html#:~:text= “Having” 是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在 Having 中可以使用聚合函数。 在说区别之前，得先介绍 GROUP,BY 这个子句，而在说 GROUP 子句前，又得先说说 “聚合函数”——SQL 语言中一种特殊的函数。例如 SUM%2C COUNT%2C MAX%2C AVG...</div><a href="/2022/11/06/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/%E5%AE%9E%E8%AE%AD3-%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2Select%E4%B9%8B%E4%B8%80/" itemprop="url" title="未命名" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/06/computer-science/base/AiForStorage/note/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gipeuibk9fj20zk0m8ay2.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-06 17:52:38"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-06T17:52:38+08:00">2022-11-06</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>65</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/06/computer-science/base/AiForStorage/note/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt"># 第一次任务 https://blog.csdn.net/qq_40714949/article/details/115393592</div><a href="/2022/11/06/computer-science/base/AiForStorage/note/" itemprop="url" title="未命名" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/06/ai/pytorch/note/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1giph4fomxoj20zk0m8axp.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-06 09:11:32"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-06T09:11:32+08:00">2022-11-06</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2.9k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/11/06/ai/pytorch/note/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt">x = torch.ones(2, 2, requires_grad=True)y = torch.ones(2, 2)x.requires_grad #Truey.requires_grad #False只有在建立张量的时候设置了 requires_grad=True ，才会追踪梯度 # 报错 # 1.Autograd：自动求导 https://blog.csdn.net/qq_39208832/article/details/117415229 ​ torch.Tensor 是这个包的核心类。如果设置它的属性 .requires_grad 为 True...</div><a href="/2022/11/06/ai/pytorch/note/" itemprop="url" title="未命名" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/03/computer-science/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/2020/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1gicliierfjj20zk0m8npd.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-03 17:50:13"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-03T17:50:13+08:00">2022-11-03</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>16</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/03/computer-science/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/2020/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt">CPU 发出的虚拟地址为逻辑地址，</div><a href="/2022/11/03/computer-science/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/2020/" itemprop="url" title="未命名" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/01/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%AC%94%E8%AE%B0/" itemprop="url" title="未命名"><img data-src="https://tva3.sinaimg.cn/mw690/6833939bly1giclgi503lj20zk0m8hdt.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-01 21:57:40"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-01T21:57:40+08:00">2022-11-01</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>57</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/01/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%AC%94%E8%AE%B0/" itemprop="url" title="未命名">未命名</a></h3><div class="excerpt"># 第二章 PPT15，元组的连串 中，数据怎么处理，上面只是说明了列的属性 PPT27 元组和连串怎么和笛卡尔积的表示相同</div><a href="/2022/11/01/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%AC%94%E8%AE%B0/" itemprop="url" title="未命名" class="btn">more...</a></div></article></div></div><nav class="pagination"><div class="inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" href="/page/2/"><i class="ic i-angle-right" aria-label="下一页"></i></a></div></nav></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">189</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">32</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">39</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/page/2/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/cv/" title="分类于 cv">cv</a></div><span><a href="/2022/08/25/ai/cv/MobileNet/" title="MobileNet">MobileNet</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/10/31/computer-science/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E6%A1%88%E4%BE%8B/2016/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/10/17/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/%E7%AC%94%E8%AE%B0/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/huggingface/" title="分类于 huggingface">huggingface</a></div><span><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" title="NLP和transformer大类概述">NLP和transformer大类概述</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/08/30/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/11/01/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%AC%94%E8%AE%B0/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Python/" title="分类于 Python">Python</a></div><span><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97os-system/" title="Python模块os.system()">Python模块os.system()</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/09/27/computer-science/base/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E4%BB%BB%E5%8A%A1%E6%96%87%E6%A1%A3/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/10/17/computer-science/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E8%AE%BA%E6%96%87/%E5%87%86%E5%A4%87/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/08/30/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/" title="未命名">未命名</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">1.1m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">16:32</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>