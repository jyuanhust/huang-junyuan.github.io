<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://huang-junyuan.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://huang-junyuan.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://huang-junyuan.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="深度学习,神经网络"><link rel="canonical" href="https://huang-junyuan.github.io/2022/07/25/ai/base/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8B%E7%BB%8D/"><title>神经网络的介绍 - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">神经网络的介绍</h1><div class="meta"><span class="item" title="创建时间：2022-07-25 17:47:48"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-07-25T17:47:48+08:00">2022-07-25</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>3k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>3 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gipesx5fdwj20zk0m81kx.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicis081o9j20zk0m8dmr.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicitcxhpij20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1giph4lm9i7j20zk0m84qp.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1giclh0m9pdj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicis3attqj20zk0m8k7l.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="分类于 ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://huang-junyuan.github.io/2022/07/25/ai/base/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8B%E7%BB%8D/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h1 id="神经网络的介绍"><a class="anchor" href="#神经网络的介绍">#</a> 神经网络的介绍</h1><h2 id="目标"><a class="anchor" href="#目标">#</a> 目标</h2><ol><li>知道神经网络的概念</li><li>知道什么是神经元</li><li>知道什么是单层神经网络</li><li>知道什么是感知机</li><li>知道什么是多层神经网络</li><li>知道激活函数是什么，有什么作用</li><li>理解神经网络的思想</li></ol><h2 id="1-人工神经网络的概念"><a class="anchor" href="#1-人工神经网络的概念">#</a> 1. 人工神经网络的概念</h2><p><strong>人工神经网络</strong>（英语：Artificial Neural Network，ANN），简称<strong>神经网络</strong>（Neural Network，NN）或<strong>类神经网络</strong>，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型，用于对函数进行估计或近似。</p><p>和其他机器学习方法一样，神经网络已经被用于解决各种各样的问题，例如机器视觉和语音识别。这些问题都是很难被传统基于规则的编程所解决的。</p><h2 id="2-神经元的概念"><a class="anchor" href="#2-神经元的概念">#</a> 2. 神经元的概念</h2><p>在生物神经网络中，每个神经元与其他神经元相连，当它 “兴奋” 时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个 “阈值”，那么它就会被激活，即 “兴奋” 起来，向其他神经元发送化学物质。</p><p>1943 年，McCulloch 和 Pitts 将上述情形抽象为上图所示的简单模型，这就是一直沿用至今的 <strong>M-P 神经元模型</strong>。把许多这样的神经元按一定的层次结构连接起来，就得到了神经网络。</p><p>一个简单的神经元如下图所示，</p><p><img data-src="/../images/1.1/%E7%A5%9E%E7%BB%8F%E5%85%83.png" alt></p><p>其中：</p><ol><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>…</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">a_1,a_2\dots a_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为各个输入的分量</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo>⋯</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_1,w_2 \cdots w_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为各个输入分量对应的权重参数</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span> 为偏置</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span></span></span></span> 为<strong>激活函数</strong>，常见的激活函数有 tanh，sigmoid，relu</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> 为神经元的输出</li></ol><p>使用数学公式表示就是：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>t</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msup><mi>W</mi><mi>T</mi></msup><mi>A</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t = f(W^TA+b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span></p><p>可见，<strong>一个神经元的功能是求得输入向量与权向量的内积后，经一个非线性传递函数得到一个标量结果</strong>。</p><h2 id="3-单层神经网络"><a class="anchor" href="#3-单层神经网络">#</a> 3. 单层神经网络</h2><p>是最基本的神经元网络形式，由有限个神经元构成，所有神经元的输入向量都是同一个向量。由于每一个神经元都会产生一个标量结果，所以单层神经元的输出是一个向量，向量的维数等于神经元的数目。</p><p>示意图如下：</p><p><img data-src="/../images/1.1/%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png" alt></p><h2 id="4-感知机"><a class="anchor" href="#4-感知机">#</a> 4. 感知机</h2><p>感知机由<strong>两层神经网</strong>络组成，<strong>输入层</strong>接收外界输入信号后传递给<strong>输出层（输出 + 1 正例，-1 反例）</strong>，输出层是 M-P 神经元</p><p><img data-src="/../images/1.1/%E6%84%9F%E7%9F%A5%E6%9C%BA.png" alt></p><p>其中从<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>1</mn></msub><mo>⋯</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_0,w_1\cdots w_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 都表示权重</p><p><strong>感知机的作用：</strong></p><p>把一个 n 维向量空间用一个超平面分割成两部分，给定一个输入向量，超平面可以判断出这个向量位于超平面的哪一边，得到输入时正类或者是反类，<strong>对应到 2 维空间就是一条直线把一个平面分为两个部分</strong>。</p><h2 id="5-多层神经网络"><a class="anchor" href="#5-多层神经网络">#</a> 5. 多层神经网络</h2><p>多层神经网络就是由单层神经网络进行叠加之后得到的，所以就形成了<strong>层</strong>的概念，常见的多层神经网络有如下结构：</p><ul><li>输入层（Input layer），众多神经元（Neuron）接受大量输入消息。输入的消息称为输入向量。</li><li>输出层（Output layer），消息在神经元链接中传输、分析、权衡，形成输出结果。输出的消息称为输出向量。</li><li>隐藏层（Hidden layer），简称 “隐层”，是输入层和输出层之间众多神经元和链接组成的各个层面。隐层可以有一层或多层。隐层的节点（神经元）数目不定，但数目越多神经网络的非线性越显著，从而神经网络的强健性（robustness）更显著。</li></ul><p>示意图如下：</p><p><img data-src="/../images/1.1/%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png" alt></p><p><strong>概念：全连接层</strong></p><p>全连接层：当前一层和前一层每个神经元相互链接，我们称当前这一层为全连接层。</p><p>思考：假设第 N-1 层有 m 个神经元，第 N 层有 n 个神经元，当第 N 层是全连接层的时候，则 N-1 和 N 层之间有 1，这些参数可以如何表示？</p><p><img data-src="/../images/1.1/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82.png" alt></p><p>从上图可以看出，所谓的全连接层就是在前一层的输出的基础上进行一次<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>W</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Y=Wx+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span> 的变化 (不考虑激活函数的情况下就是一次线性变化，所谓线性变化就是平移 (+b) 和缩放的组合 (*w))</p><h2 id="6-激活函数"><a class="anchor" href="#6-激活函数">#</a> 6. 激活函数</h2><p>在前面的神经元的介绍过程中我们提到了激活函数，那么他到底是干什么的呢？</p><p>假设我们有这样一组数据，三角形和四边形，需要把他们分为两类</p><p><img data-src="/../images/1.1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B01.png" alt></p><p>通过不带激活函数的感知机模型我们可以划出一条线，把平面分割开</p><p><img data-src="/../images/1.1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B02.png" alt></p><p>假设我们确定了参数 w 和 b 之后，那么带入需要预测的数据，如果 y&gt;0, 我们认为这个点在直线的右边，也就是正类（三角形），否则是在左边（四边形）</p><p>但是可以看出，三角形和四边形是没有办法通过直线分开的，那么这个时候该怎么办？</p><p>可以考虑使用多层神经网络来进行尝试，比如<strong>在前面的感知机模型中再增加一层</strong></p><p><img data-src="/../images/1.1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B03.png" alt></p><p>对上图中的等式进行合并，我们可以得到：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>−</mo><mn>11</mn></mrow></msub><msub><mi>w</mi><mrow><mn>2</mn><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo>⋯</mo><mtext></mtext><mo stretchy="false">)</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>−</mo><mn>21</mn></mrow></msub><msub><mi>w</mi><mrow><mn>2</mn><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo>⋯</mo><mtext></mtext><mo stretchy="false">)</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mn>2</mn><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo>⋯</mo><mtext></mtext><mo stretchy="false">)</mo><msub><mi>b</mi><mrow><mn>1</mn><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">y = (w_{1-11}w_{2-1}+\cdots)x_1+(w_{1-21}w_{2-1}+\cdots)x_2 + (w_{2-1}+\cdots)b_{1-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight">2</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span></span></span></span></span></p><p>上式括号中的都为 w 参数，和公式<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y = w_1x_1 + w_2x_2 +b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span> 完全相同，依然只能够绘制出直线</p><p>所以可以发现，即使是多层神经网络，相比于前面的感知机，没有任何的改进。</p><p>但是如果此时，我们在前面感知机的基础上加上<strong>非线性的激活函数</strong>之后，输出的结果就不在是一条直线</p><p><img data-src="/../images/1.1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B04.png" alt></p><p>如上图，右边是 sigmoid 函数，对感知机的结果，通过 sigmoid 函数进行处理</p><p>如果给定合适的参数 w 和 b，就可以得到合适的曲线，能够完成对最开始问题的非线性分割</p><p>所以激活函数很重要的一个<strong>作用</strong>就是<strong>增加模型的非线性分割能力</strong></p><p>常见的激活函数有：</p><p><img data-src="/../images/1.1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B05.jpg" alt></p><p>看图可知：</p><ul><li>sigmoid 只会输出正数，以及靠近 0 的输出变化率最大</li><li>tanh 和 sigmoid 不同的是，tanh 输出可以是负数</li><li>Relu 是输入只能大于 0, 如果你输入含有负数，Relu 就不适合，如果你的输入是图片格式，Relu 就挺常用的，因为图片的像素值作为输入时取值为 [0,255]。</li></ul><p>激活函数的作用除了前面说的<strong>增加模型的非线性分割能力</strong>外，还有</p><ul><li><strong>提高模型鲁棒性</strong></li><li><strong>缓解梯度消失问题</strong></li><li><strong>加速模型收敛等</strong></li></ul><p>这些好处，大家后续会慢慢体会到，这里先知道就行</p><h2 id="6-神经网络示例"><a class="anchor" href="#6-神经网络示例">#</a> 6. 神经网络示例</h2><p>一个男孩想要找一个女朋友，于是实现了一个<strong>女友判定机</strong>，随着年龄的增长，他的判定机也一直在变化</p><p>14 岁的时候：</p><p><img data-src="/../images/1.1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%901.png" alt></p><p>无数次碰壁之后，男孩意识到追到女孩的可能性和颜值一样重要，于是修改了判定机：</p><p><img data-src="/../images/1.1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%902.png" alt></p><p>在 15 岁的时候终于找到呢女朋友，但是一顿时间后他发现有各种难以忍受的习惯，最终决定分手。一段空窗期中，他发现找女朋友很复杂，需要更多的条件才能够帮助他找到女朋友，于是在 25 岁的时候，他再次修改了判定机：</p><p><img data-src="/../images/1.1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%903.png" alt></p><p>在更新了女友判定机之后，问题又来了，很多指标不能够很好的量化，如何颜值，什么样的叫做颜值高，什么样的叫做性格好等等，为了解决这个问题，他又更新了判定机，最终得到<strong>超级女友判定机</strong></p><p><img data-src="/../images/1.1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%904.png" alt></p><p>上述的超级女友判定机其实就是神经网络，它能够接受基础的输入，通过隐藏层的线性的和非线性的变化最终的到输出</p><p>通过上面例子，希望大家能够理解深度学习的<strong>思想</strong>：</p><p>输出的最原始、最基本的数据，通过模型来进行特征工程，进行更加高级特征的学习，然后通过传入的数据来确定合适的参数，让模型去更好的拟合数据。</p><p>这个过程可以理解为盲人摸象，多个人一起摸，把摸到的结果乘上合适的权重，进行合适的变化，让他和目标值趋近一致。整个过程只需要输入基础的数据，程序自动寻找合适的参数。</p><div class="tags"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 深度学习</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="ic i-tag"></i> 神经网络</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-08-30 11:10:22" itemprop="dateModified" datetime="2022-08-30T11:10:22+08:00">2022-08-30</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://huang-junyuan.github.io/2022/07/25/ai/base/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8B%E7%BB%8D/" title="神经网络的介绍">https://huang-junyuan.github.io/2022/07/25/ai/base/神经网络的介绍/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/07/25/ai/base/jupyter-notebook%E4%BD%BF%E7%94%A8/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gicitf0kl1j20zk0m87fe.jpg" title="jupyter notebook使用"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 工具</span><h3>jupyter notebook使用</h3></a></div><div class="item right"><a href="/2022/07/25/ai/nlp/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giph4baakhj20zk0m8h5q.jpg" title="循环神经网络基础"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> nlp</span><h3>循环神经网络基础</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">神经网络的介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87"><span class="toc-number">1.1.</span> <span class="toc-text">目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">1.2.</span> <span class="toc-text">1. 人工神经网络的概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">1.3.</span> <span class="toc-text">2. 神经元的概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.</span> <span class="toc-text">3. 单层神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="toc-number">1.5.</span> <span class="toc-text">4. 感知机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.6.</span> <span class="toc-text">5. 多层神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.7.</span> <span class="toc-text">6. 激活函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.8.</span> <span class="toc-text">6. 神经网络示例</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/07/21/ai/cv/OpenCV%E8%BD%AE%E5%BB%93%E6%A3%80%E6%B5%8B/" rel="bookmark" title="OpenCV轮廓检测">OpenCV轮廓检测</a></li><li><a href="/2022/07/21/ai/cv/ncnn%E5%9C%A8window%EF%BC%8Cvs2019%EF%BC%8Ccmake-3-16-5-win64-x64%E7%BC%96%E8%AF%91/" rel="bookmark" title="ncnn在window，vs2019，cmake-3.16.5-win64-x64编译">ncnn在window，vs2019，cmake-3.16.5-win64-x64编译</a></li><li><a href="/2022/07/21/ai/cv/OpenCV%E6%95%99%E7%A8%8B/" rel="bookmark" title="OpenCV教程">OpenCV教程</a></li><li><a href="/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/" rel="bookmark" title="pytorch入门">pytorch入门</a></li><li><a href="/2022/07/22/ai/cv/ncnn%E5%92%8Copencv%E5%9C%A8vs2022%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B/" rel="bookmark" title="ncnn和opencv在vs2022上创建工程推理示例">ncnn和opencv在vs2022上创建工程推理示例</a></li><li><a href="/2022/07/25/ai/pytorch/%E4%BD%BF%E7%94%A8Pytorch%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" rel="bookmark" title="使用Pytorch实现手写数字识别">使用Pytorch实现手写数字识别</a></li><li><a href="/2022/07/25/ai/pytorch/argmax-torch/" rel="bookmark" title="argmax-torch">argmax-torch</a></li><li class="active"><a href="/2022/07/25/ai/base/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8B%E7%BB%8D/" rel="bookmark" title="神经网络的介绍">神经网络的介绍</a></li><li><a href="/2022/07/25/ai/nlp/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" rel="bookmark" title="循环神经网络基础">循环神经网络基础</a></li><li><a href="/2022/08/05/ai/nlp/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" rel="bookmark" title="文本情感分类">文本情感分类</a></li><li><a href="/2022/08/05/ai/nlp/Summarization-huggingface/" rel="bookmark" title="Summarization - huggingface">Summarization - huggingface</a></li><li><a href="/2022/08/24/ai/cv/face-alignment%EF%BC%9Aface-alignment%E5%BA%93%E7%9A%84%E7%AE%80%E4%BB%8B%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" rel="bookmark" title="face_alignment：face_alignment库的简介、安装、使用方法">face_alignment：face_alignment库的简介、安装、使用方法</a></li><li><a href="/2022/08/24/ai/nlp/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" rel="bookmark" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系">PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系</a></li><li><a href="/2022/08/24/ai/nlp/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" rel="bookmark" title="pytorch中LSTM的output和hidden关系">pytorch中LSTM的output和hidden关系</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" rel="bookmark" title="Pytorch中transforms.RandomResizedCrop()等图像操作">Pytorch中transforms.RandomResizedCrop()等图像操作</a></li><li><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" rel="bookmark" title="pytorch中的transpose方法（函数）">pytorch中的transpose方法（函数）</a></li><li><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" rel="bookmark" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()">PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" rel="bookmark" title="Pytorch函数expand()详解">Pytorch函数expand()详解</a></li><li><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" rel="bookmark" title="pytorch固定随机种子-训练稳定复现">pytorch固定随机种子-训练稳定复现</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" rel="bookmark" title="Pytorch的data.norm（几种范数(norm)的详细介绍）">Pytorch的data.norm（几种范数(norm)的详细介绍）</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" rel="bookmark" title="Pytorch通过requires_grad固定部分参数进行网络训练">Pytorch通过requires_grad固定部分参数进行网络训练</a></li><li><a href="/2022/08/24/ai/pytorch/torch-matmul-%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D/" rel="bookmark" title="torch.matmul()用法介绍">torch.matmul()用法介绍</a></li><li><a href="/2022/08/24/ai/pytorch/torchvision-datasets-ImageFolder/" rel="bookmark" title="torchvision.datasets.ImageFolder">torchvision.datasets.ImageFolder</a></li><li><a href="/2022/08/24/ai/cv/%E7%AE%80%E5%8D%95%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE/" rel="bookmark" title="简单计算图片数据集的均值和方差">简单计算图片数据集的均值和方差</a></li><li><a href="/2022/08/25/ai/cv/GAN/" rel="bookmark" title="GAN">GAN</a></li><li><a href="/2022/08/25/ai/cv/MobileNet/" rel="bookmark" title="MobileNet">MobileNet</a></li><li><a href="/2022/08/25/ai/nlp/transformer/" rel="bookmark" title="transformer">transformer</a></li><li><a href="/2022/08/25/ai/base/Evaluation-metrics-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/" rel="bookmark" title="Evaluation metrics——机器学习中常见的评估指标">Evaluation metrics——机器学习中常见的评估指标</a></li><li><a href="/2022/08/25/ai/cv/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/" rel="bookmark" title="语义分割">语义分割</a></li><li><a href="/2022/08/25/ai/nlp/nlp%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/" rel="bookmark" title="nlp的数据集">nlp的数据集</a></li><li><a href="/2022/09/02/ai/base/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/" rel="bookmark" title="模型微调 Fine Tune">模型微调 Fine Tune</a></li><li><a href="/2022/09/07/ai/cv/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" rel="bookmark" title="图像分类">图像分类</a></li><li><a href="/2022/09/07/ai/nlp/%E8%AE%AD%E7%BB%83CLM/" rel="bookmark" title="Training a causal language model from scratch">Training a causal language model from scratch</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">129</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">27</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">38</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/07/25/ai/base/jupyter-notebook%E4%BD%BF%E7%94%A8/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/07/25/ai/nlp/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="分类于 后端">后端</a></div><span><a href="/2022/08/24/backend/django/%E8%AE%BF%E9%97%AEdjango%E5%90%8E%E5%8F%B0%EF%BC%8C%E6%8F%90%E7%A4%BACSRF%E9%AA%8C%E8%AF%81%E5%A4%B1%E8%B4%A5-%E8%AF%B7%E6%B1%82%E8%A2%AB%E4%B8%AD%E6%96%AD-Referer-checking-failed-does-not-match-any-trust/" title="访问django后台，提示CSRF验证失败._请求被中断.Referer_checking_failed_-_does_not_match_any_trust">访问django后台，提示CSRF验证失败._请求被中断.Referer_checking_failed_-_does_not_match_any_trust</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/08/30/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%BF%90%E7%AE%97/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/Node-js/" title="分类于 Node.js">Node.js</a></div><span><a href="/2022/09/08/frontend/Node/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81/" title="数据库与身份认证">数据库与身份认证</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/" title="分类于 计算机科学">计算机科学</a></div><span><a href="/2022/08/24/computer-science/algorithm/base/%E7%AE%97%E6%B3%951/" title="算法1">算法1</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/Node-js/" title="分类于 Node.js">Node.js</a></div><span><a href="/2022/09/08/frontend/Node/%E5%88%9D%E8%AF%86Node%E5%8F%8A%E5%85%B6%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/" title="初识Node及其内置模块">初识Node及其内置模块</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/08/26/frontend/vue/vue%E7%9A%84%E6%89%A9%E5%B1%95%E8%BF%90%E7%AE%97%E7%AC%A6/" title="vue的扩展运算符">vue的扩展运算符</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a></div><span><a href="/2022/09/02/frontend/base/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%B0%83%E8%AF%95/" title="浏览器调试">浏览器调试</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Python/" title="分类于 Python">Python</a></div><span><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97os-system/" title="Python模块os.system()">Python模块os.system()</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/09/03/ai/nlp/transformers%E5%8C%85%E4%BD%BF%E7%94%A8/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a></div><span><a href="/2022/07/25/frontend/javascript/JavaScript/" title="JavaScript">JavaScript</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">862k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">13:03</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/07/25/ai/base/神经网络的介绍/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>